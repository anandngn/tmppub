{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e1cd147",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API and AWS Sagemaker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85592c17",
   "metadata": {},
   "source": [
    "In this notebook, you will train and evaluate different models using the [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/) and [AWS Sagemaker](https://aws.amazon.com/sagemaker/). \n",
    "\n",
    "If you ever feel stuck, you can refer to this [tutorial](https://aws.amazon.com/blogs/machine-learning/training-and-deploying-models-using-tensorflow-2-with-the-object-detection-api-on-amazon-sagemaker/).\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We are using the [Waymo Open Dataset](https://waymo.com/open/) for this project. The dataset has already been exported using the tfrecords format. The files have been created following the format described [here](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records). You can find data stored on [AWS S3](https://aws.amazon.com/s3/), AWS Object Storage. The images are saved with a resolution of 640x640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc1d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install tensorflow_io sagemaker -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f55350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from framework import CustomFramework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccde6fd1",
   "metadata": {},
   "source": [
    "Save the IAM role in a variable called `role`. This would be useful when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab6b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::503561426851:role/service-role/AmazonSageMaker-ExecutionRole-20250610T144701\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae64e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train and val paths below are public S3 buckets created by Udacity for this project\n",
    "inputs = {'train': 's3://cd2688-object-detection-tf2/train/', \n",
    "          'val': 's3://cd2688-object-detection-tf2/val/'} \n",
    "\n",
    "# Insert path of a folder in your personal S3 bucket to store tensorboard logs.\n",
    "tensorboard_s3_prefix = 's3://object-detection-rcnnr50/logs/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc16a825",
   "metadata": {},
   "source": [
    "## Container\n",
    "\n",
    "To train the model, you will first need to build a [docker](https://www.docker.com/) container with all the dependencies required by the TF Object Detection API. The code below does the following:\n",
    "* clone the Tensorflow models repository\n",
    "* get the exporter and training scripts from the repository\n",
    "* build the docker image and push it \n",
    "* print the container name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad5ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'docker/models'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# clone the repo and get the scripts\n",
    "git clone https://github.com/tensorflow/models.git docker/models\n",
    "\n",
    "# get model_main and exporter_main files from TF2 Object Detection GitHub repository\n",
    "cp docker/models/research/object_detection/exporter_main_v2.py source_dir \n",
    "cp docker/models/research/object_detection/model_main_tf2.py source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2dab3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Building image with name tf2-object-detection\n",
      "Pushing image to ECR 503561426851.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20250610233323\n",
      "The push refers to repository [503561426851.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection]\n",
      "\n",
      "\u001b[1B17553b7f: Preparing \n",
      "\u001b[1B0735d106: Preparing \n",
      "\u001b[1B85b285e9: Preparing \n",
      "\u001b[1B1c7a2546: Preparing \n",
      "\u001b[1B9ed3e593: Preparing \n",
      "\u001b[1Bf7b0c61c: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1Bb4904462: Preparing \n",
      "\u001b[1Ba0102bd4: Preparing \n",
      "\u001b[1Bfa4342ce: Preparing \n",
      "\u001b[1Ba40e4dcd: Preparing \n",
      "\u001b[1Bb5695a98: Preparing \n",
      "\u001b[1Bf0d116f4: Preparing \n",
      "\u001b[1B2813a979: Preparing \n",
      "\u001b[1B6e868aa5: Preparing \n",
      "\u001b[1B136c7d36: Preparing \n",
      "\u001b[1B891e0e76: Preparing \n",
      "\u001b[1Bed848ac5: Preparing \n",
      "\u001b[1B18b47754: Preparing \n",
      "\u001b[1B91e05b94: Preparing \n",
      "\u001b[1Be103257c: Preparing \n",
      "\u001b[1Bb25399cb: Preparing \n",
      "\u001b[1Bb667a965: Preparing \n",
      "\u001b[17B4904462: Waiting g \n",
      "\u001b[1Bb4e1ecd1: Preparing \n",
      "\u001b[1B5c845fcf: Preparing \n",
      "\u001b[19B0102bd4: Waiting g \n",
      "\u001b[10B20250610233323: digest: sha256:cd0347752c49f8f7a2a3ad9f0186c6ce0ea58440e1eda5a36868de9706d273df size: 6187\n",
      "Saving ECR image URI into ecr_image_fullname.txt\n"
     ]
    }
   ],
   "source": [
    "# build and push the docker image. This code can be commented out after being run once.\n",
    "# This will take around 10 mins.\n",
    "image_name = 'tf2-object-detection'\n",
    "!sh ./docker/build_and_push.sh $image_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e62b3562",
   "metadata": {},
   "source": [
    "To verify that the image was correctly pushed to the [Elastic Container Registry](https://aws.amazon.com/ecr/), you can look at it in the AWS webapp. For example, below you can see that three different images have been pushed to ECR. You should only see one, called `tf2-object-detection`.\n",
    "![ECR Example](../data/example_ecr.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0310b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503561426851.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20250610233323\n"
     ]
    }
   ],
   "source": [
    "# display the container name\n",
    "with open (os.path.join('docker', 'ecr_image_fullname.txt'), 'r') as f:\n",
    "    container = f.readlines()[0][:-1]\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13b2a754",
   "metadata": {},
   "source": [
    "## Pre-trained model from model zoo\n",
    "\n",
    "As often, we are not training from scratch and we will be using a pretrained model from the TF Object Detection model zoo. You can find pretrained checkpoints [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Because your time is limited for this project, we recommend to only experiment with the following models:\n",
    "* SSD MobileNet V2 FPNLite 640x640\t\n",
    "* SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\t\n",
    "* Faster R-CNN ResNet50 V1 640x640\t\n",
    "* EfficientDet D1 640x640\t\n",
    "* Faster R-CNN ResNet152 V1 640x640\t\n",
    "\n",
    "In the code below, the EfficientDet D1 model is downloaded and extracted. This code should be adjusted if you were to experiment with other architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# EfficientDet D1 640x640\n",
    "\n",
    "%%bash\n",
    "mkdir /tmp/checkpoint\n",
    "mkdir source_dir/checkpoint\n",
    "wget -O /tmp/efficientdet.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
    "tar -zxvf /tmp/efficientdet.tar.gz --strip-components 2 --directory source_dir/checkpoint efficientdet_d1_coco17_tpu-32/checkpoint\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00f7745-d37f-43a9-a9fc-6ef34a54e8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-06-10 23:53:13--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.163.207, 142.251.167.207, 172.253.115.207, ...\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.163.207|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20518283 (20M) [application/x-tar]\n",
      "Saving to: ‘/tmp/mobilenet.tar.gz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 12.5M 2s\n",
      "    50K .......... .......... .......... .......... ..........  0% 24.8M 1s\n",
      "   100K .......... .......... .......... .......... ..........  0% 25.1M 1s\n",
      "   150K .......... .......... .......... .......... ..........  0% 53.7M 1s\n",
      "   200K .......... .......... .......... .......... ..........  1% 45.6M 1s\n",
      "   250K .......... .......... .......... .......... ..........  1% 69.7M 1s\n",
      "   300K .......... .......... .......... .......... ..........  1%  155M 1s\n",
      "   350K .......... .......... .......... .......... ..........  1% 80.5M 1s\n",
      "   400K .......... .......... .......... .......... ..........  2%  134M 1s\n",
      "   450K .......... .......... .......... .......... ..........  2%  172M 0s\n",
      "   500K .......... .......... .......... .......... ..........  2%  110M 0s\n",
      "   550K .......... .......... .......... .......... ..........  2%  258M 0s\n",
      "   600K .......... .......... .......... .......... ..........  3%  145M 0s\n",
      "   650K .......... .......... .......... .......... ..........  3%  238M 0s\n",
      "   700K .......... .......... .......... .......... ..........  3%  293M 0s\n",
      "   750K .......... .......... .......... .......... ..........  3%  119M 0s\n",
      "   800K .......... .......... .......... .......... ..........  4%  185M 0s\n",
      "   850K .......... .......... .......... .......... ..........  4%  173M 0s\n",
      "   900K .......... .......... .......... .......... ..........  4%  267M 0s\n",
      "   950K .......... .......... .......... .......... ..........  4%  257M 0s\n",
      "  1000K .......... .......... .......... .......... ..........  5%  233M 0s\n",
      "  1050K .......... .......... .......... .......... ..........  5%  270M 0s\n",
      "  1100K .......... .......... .......... .......... ..........  5%  245M 0s\n",
      "  1150K .......... .......... .......... .......... ..........  5%  272M 0s\n",
      "  1200K .......... .......... .......... .......... ..........  6%  228M 0s\n",
      "  1250K .......... .......... .......... .......... ..........  6%  269M 0s\n",
      "  1300K .......... .......... .......... .......... ..........  6%  255M 0s\n",
      "  1350K .......... .......... .......... .......... ..........  6%  246M 0s\n",
      "  1400K .......... .......... .......... .......... ..........  7%  228M 0s\n",
      "  1450K .......... .......... .......... .......... ..........  7%  307M 0s\n",
      "  1500K .......... .......... .......... .......... ..........  7%  273M 0s\n",
      "  1550K .......... .......... .......... .......... ..........  7%  332M 0s\n",
      "  1600K .......... .......... .......... .......... ..........  8%  258M 0s\n",
      "  1650K .......... .......... .......... .......... ..........  8%  274M 0s\n",
      "  1700K .......... .......... .......... .......... ..........  8%  294M 0s\n",
      "  1750K .......... .......... .......... .......... ..........  8%  298M 0s\n",
      "  1800K .......... .......... .......... .......... ..........  9%  242M 0s\n",
      "  1850K .......... .......... .......... .......... ..........  9%  260M 0s\n",
      "  1900K .......... .......... .......... .......... ..........  9%  286M 0s\n",
      "  1950K .......... .......... .......... .......... ..........  9%  274M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 10%  264M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 10%  311M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 10%  307M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 10%  269M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 11%  227M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 11%  289M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 11%  282M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 11%  317M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 12%  222M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 12%  326M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 12%  287M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 12%  286M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 13%  225M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 13%  294M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 13%  288M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 13%  249M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 14%  239M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 14%  253M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 14%  239M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 14%  277M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 15%  237M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 15%  271M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 15%  324M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 15%  328M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 16%  271M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 16%  264M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 16%  315M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 16%  311M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 17%  261M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 17%  282M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 17%  317M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 17%  286M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 18%  249M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 18%  320M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 18%  324M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 18%  302M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 19%  248M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 19%  263M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 19%  310M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 19%  335M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 20%  241M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 20%  865K 0s\n",
      "  4100K .......... .......... .......... .......... .......... 20%  171M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 20%  307M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 21%  357M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 21%  277M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 21%  229M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 21%  318M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 22%  302M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 22%  272M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 22%  217M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 22%  272M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 23%  255M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 23%  243M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 23%  214M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 23%  251M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 24%  254M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 24%  264M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 24%  230M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 24%  320M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 25%  323M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 25%  317M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 25%  257M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 25%  245M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 26%  307M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 26%  252M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 26%  284M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 26%  291M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 27%  266M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 27%  290M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 27%  211M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 27%  244M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 28%  224M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 28%  266M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 28%  214M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 28%  270M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 29%  322M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 29%  315M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 29%  239M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 29%  318M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 30%  294M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 30%  306M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 30%  245M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 30%  313M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 31%  173M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 31%  301M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 31%  308M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 31%  253M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 32%  253M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 32%  263M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 32%  275M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 32%  302M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 33%  264M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 33%  279M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 33%  290M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 33%  314M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 34%  231M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 34%  309M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 34%  278M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 34%  291M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 35%  207M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 35%  268M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 35%  261M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 35%  241M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 36%  239M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 36%  313M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 36%  340M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 36%  295M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 37%  241M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 37%  339M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 37%  348M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 37%  318M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 38%  218M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 38%  291M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 38%  237M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 38%  339M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 39%  262M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 39%  284M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 39% 30.2M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 39% 82.9M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 40%  320M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 40%  215M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 40%  265M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 40%  328M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 41%  263M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 41%  261M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 41%  283M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 41%  242M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 42%  284M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 42%  251M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 42%  276M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 42%  278M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 43%  278M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 43%  248M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 43%  261M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 43%  278M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 44%  255M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 44%  248M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 44%  288M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 44%  278M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 45%  280M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 45%  242M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 45%  275M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 45%  214M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 46%  281M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 46%  232M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 46%  253M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 46%  272M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 47%  263M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 47%  226M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 47%  274M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 47%  285M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 48%  266M 0s\n",
      "  9650K .......... .......... .......... .......... .......... 48%  249M 0s\n",
      "  9700K .......... .......... .......... .......... .......... 48%  264M 0s\n",
      "  9750K .......... .......... .......... .......... .......... 48%  297M 0s\n",
      "  9800K .......... .......... .......... .......... .......... 49%  268M 0s\n",
      "  9850K .......... .......... .......... .......... .......... 49%  258M 0s\n",
      "  9900K .......... .......... .......... .......... .......... 49%  273M 0s\n",
      "  9950K .......... .......... .......... .......... .......... 49%  278M 0s\n",
      " 10000K .......... .......... .......... .......... .......... 50%  266M 0s\n",
      " 10050K .......... .......... .......... .......... .......... 50%  236M 0s\n",
      " 10100K .......... .......... .......... .......... .......... 50%  261M 0s\n",
      " 10150K .......... .......... .......... .......... .......... 50%  271M 0s\n",
      " 10200K .......... .......... .......... .......... .......... 51%  246M 0s\n",
      " 10250K .......... .......... .......... .......... .......... 51%  278M 0s\n",
      " 10300K .......... .......... .......... .......... .......... 51%  260M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 51%  276M 0s\n",
      " 10400K .......... .......... .......... .......... .......... 52%  267M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 52%  267M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 52%  247M 0s\n",
      " 10550K .......... .......... .......... .......... .......... 52%  280M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 53%  346M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 53%  219M 0s\n",
      " 10700K .......... .......... .......... .......... .......... 53%  318M 0s\n",
      " 10750K .......... .......... .......... .......... .......... 53%  327M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 54%  288M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 54%  257M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 54%  250M 0s\n",
      " 10950K .......... .......... .......... .......... .......... 54%  260M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 55%  272M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 55%  239M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 55%  289M 0s\n",
      " 11150K .......... .......... .......... .......... .......... 55%  271M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 56%  276M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 56%  263M 0s\n",
      " 11300K .......... .......... .......... .......... .......... 56%  260M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 56%  286M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 57%  196M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 57%  260M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 57%  270M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 57%  255M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 58%  269M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 58%  205M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 58%  280M 0s\n",
      " 11750K .......... .......... .......... .......... .......... 58%  258M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 59%  272M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 59%  235M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 59%  332M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 59%  273M 0s\n",
      " 12000K .......... .......... .......... .......... .......... 60%  269M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 60%  235M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 60%  300M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 60%  296M 0s\n",
      " 12200K .......... .......... .......... .......... .......... 61%  277M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 61%  276M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 61%  295M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 61%  302M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 62%  307M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 62%  248M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 62%  313M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 62%  309M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 63%  270M 0s\n",
      " 12650K .......... .......... .......... .......... .......... 63%  269M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 63%  338M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 63%  272M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 64%  241M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 64%  246M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 64%  293M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 64%  301M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 65%  262M 0s\n",
      " 13050K .......... .......... .......... .......... .......... 65%  272M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 65%  248M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 65%  328M 0s\n",
      " 13200K .......... .......... .......... .......... .......... 66%  290M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 66%  278M 0s\n",
      " 13300K .......... .......... .......... .......... .......... 66%  305M 0s\n",
      " 13350K .......... .......... .......... .......... .......... 66%  289M 0s\n",
      " 13400K .......... .......... .......... .......... .......... 67%  285M 0s\n",
      " 13450K .......... .......... .......... .......... .......... 67%  240M 0s\n",
      " 13500K .......... .......... .......... .......... .......... 67%  307M 0s\n",
      " 13550K .......... .......... .......... .......... .......... 67%  315M 0s\n",
      " 13600K .......... .......... .......... .......... .......... 68%  330M 0s\n",
      " 13650K .......... .......... .......... .......... .......... 68%  271M 0s\n",
      " 13700K .......... .......... .......... .......... .......... 68%  317M 0s\n",
      " 13750K .......... .......... .......... .......... .......... 68%  347M 0s\n",
      " 13800K .......... .......... .......... .......... .......... 69%  287M 0s\n",
      " 13850K .......... .......... .......... .......... .......... 69%  273M 0s\n",
      " 13900K .......... .......... .......... .......... .......... 69%  286M 0s\n",
      " 13950K .......... .......... .......... .......... .......... 69%  266M 0s\n",
      " 14000K .......... .......... .......... .......... .......... 70%  340M 0s\n",
      " 14050K .......... .......... .......... .......... .......... 70%  250M 0s\n",
      " 14100K .......... .......... .......... .......... .......... 70%  345M 0s\n",
      " 14150K .......... .......... .......... .......... .......... 70%  313M 0s\n",
      " 14200K .......... .......... .......... .......... .......... 71%  307M 0s\n",
      " 14250K .......... .......... .......... .......... .......... 71%  281M 0s\n",
      " 14300K .......... .......... .......... .......... .......... 71%  301M 0s\n",
      " 14350K .......... .......... .......... .......... .......... 71%  294M 0s\n",
      " 14400K .......... .......... .......... .......... .......... 72%  311M 0s\n",
      " 14450K .......... .......... .......... .......... .......... 72%  272M 0s\n",
      " 14500K .......... .......... .......... .......... .......... 72%  284M 0s\n",
      " 14550K .......... .......... .......... .......... .......... 72%  357M 0s\n",
      " 14600K .......... .......... .......... .......... .......... 73%  318M 0s\n",
      " 14650K .......... .......... .......... .......... .......... 73%  275M 0s\n",
      " 14700K .......... .......... .......... .......... .......... 73%  311M 0s\n",
      " 14750K .......... .......... .......... .......... .......... 73%  324M 0s\n",
      " 14800K .......... .......... .......... .......... .......... 74%  335M 0s\n",
      " 14850K .......... .......... .......... .......... .......... 74%  263M 0s\n",
      " 14900K .......... .......... .......... .......... .......... 74%  315M 0s\n",
      " 14950K .......... .......... .......... .......... .......... 74%  291M 0s\n",
      " 15000K .......... .......... .......... .......... .......... 75%  305M 0s\n",
      " 15050K .......... .......... .......... .......... .......... 75%  284M 0s\n",
      " 15100K .......... .......... .......... .......... .......... 75%  313M 0s\n",
      " 15150K .......... .......... .......... .......... .......... 75%  308M 0s\n",
      " 15200K .......... .......... .......... .......... .......... 76%  231M 0s\n",
      " 15250K .......... .......... .......... .......... .......... 76%  277M 0s\n",
      " 15300K .......... .......... .......... .......... .......... 76%  317M 0s\n",
      " 15350K .......... .......... .......... .......... .......... 76%  346M 0s\n",
      " 15400K .......... .......... .......... .......... .......... 77%  276M 0s\n",
      " 15450K .......... .......... .......... .......... .......... 77%  223M 0s\n",
      " 15500K .......... .......... .......... .......... .......... 77%  217M 0s\n",
      " 15550K .......... .......... .......... .......... .......... 77%  309M 0s\n",
      " 15600K .......... .......... .......... .......... .......... 78%  289M 0s\n",
      " 15650K .......... .......... .......... .......... .......... 78%  259M 0s\n",
      " 15700K .......... .......... .......... .......... .......... 78%  265M 0s\n",
      " 15750K .......... .......... .......... .......... .......... 78%  317M 0s\n",
      " 15800K .......... .......... .......... .......... .......... 79%  291M 0s\n",
      " 15850K .......... .......... .......... .......... .......... 79%  276M 0s\n",
      " 15900K .......... .......... .......... .......... .......... 79%  345M 0s\n",
      " 15950K .......... .......... .......... .......... .......... 79%  319M 0s\n",
      " 16000K .......... .......... .......... .......... .......... 80%  287M 0s\n",
      " 16050K .......... .......... .......... .......... .......... 80%  270M 0s\n",
      " 16100K .......... .......... .......... .......... .......... 80%  255M 0s\n",
      " 16150K .......... .......... .......... .......... .......... 80%  311M 0s\n",
      " 16200K .......... .......... .......... .......... .......... 81%  274M 0s\n",
      " 16250K .......... .......... .......... .......... .......... 81%  242M 0s\n",
      " 16300K .......... .......... .......... .......... .......... 81%  226M 0s\n",
      " 16350K .......... .......... .......... .......... .......... 81% 80.1M 0s\n",
      " 16400K .......... .......... .......... .......... .......... 82%  201M 0s\n",
      " 16450K .......... .......... .......... .......... .......... 82%  287M 0s\n",
      " 16500K .......... .......... .......... .......... .......... 82%  257M 0s\n",
      " 16550K .......... .......... .......... .......... .......... 82%  304M 0s\n",
      " 16600K .......... .......... .......... .......... .......... 83%  279M 0s\n",
      " 16650K .......... .......... .......... .......... .......... 83%  295M 0s\n",
      " 16700K .......... .......... .......... .......... .......... 83%  351M 0s\n",
      " 16750K .......... .......... .......... .......... .......... 83%  326M 0s\n",
      " 16800K .......... .......... .......... .......... .......... 84%  272M 0s\n",
      " 16850K .......... .......... .......... .......... .......... 84%  326M 0s\n",
      " 16900K .......... .......... .......... .......... .......... 84%  133M 0s\n",
      " 16950K .......... .......... .......... .......... .......... 84%  286M 0s\n",
      " 17000K .......... .......... .......... .......... .......... 85%  307M 0s\n",
      " 17050K .......... .......... .......... .......... .......... 85%  243M 0s\n",
      " 17100K .......... .......... .......... .......... .......... 85%  291M 0s\n",
      " 17150K .......... .......... .......... .......... .......... 85%  282M 0s\n",
      " 17200K .......... .......... .......... .......... .......... 86%  295M 0s\n",
      " 17250K .......... .......... .......... .......... .......... 86%  210M 0s\n",
      " 17300K .......... .......... .......... .......... .......... 86%  303M 0s\n",
      " 17350K .......... .......... .......... .......... .......... 86%  262M 0s\n",
      " 17400K .......... .......... .......... .......... .......... 87%  258M 0s\n",
      " 17450K .......... .......... .......... .......... .......... 87%  268M 0s\n",
      " 17500K .......... .......... .......... .......... .......... 87%  314M 0s\n",
      " 17550K .......... .......... .......... .......... .......... 87%  274M 0s\n",
      " 17600K .......... .......... .......... .......... .......... 88%  283M 0s\n",
      " 17650K .......... .......... .......... .......... .......... 88%  305M 0s\n",
      " 17700K .......... .......... .......... .......... .......... 88%  263M 0s\n",
      " 17750K .......... .......... .......... .......... .......... 88%  306M 0s\n",
      " 17800K .......... .......... .......... .......... .......... 89%  360M 0s\n",
      " 17850K .......... .......... .......... .......... .......... 89%  248M 0s\n",
      " 17900K .......... .......... .......... .......... .......... 89%  265M 0s\n",
      " 17950K .......... .......... .......... .......... .......... 89%  283M 0s\n",
      " 18000K .......... .......... .......... .......... .......... 90%  285M 0s\n",
      " 18050K .......... .......... .......... .......... .......... 90%  240M 0s\n",
      " 18100K .......... .......... .......... .......... .......... 90%  274M 0s\n",
      " 18150K .......... .......... .......... .......... .......... 90%  313M 0s\n",
      " 18200K .......... .......... .......... .......... .......... 91%  276M 0s\n",
      " 18250K .......... .......... .......... .......... .......... 91%  287M 0s\n",
      " 18300K .......... .......... .......... .......... .......... 91%  297M 0s\n",
      " 18350K .......... .......... .......... .......... .......... 91%  315M 0s\n",
      " 18400K .......... .......... .......... .......... .......... 92%  284M 0s\n",
      " 18450K .......... .......... .......... .......... .......... 92%  265M 0s\n",
      " 18500K .......... .......... .......... .......... .......... 92%  348M 0s\n",
      " 18550K .......... .......... .......... .......... .......... 92%  238M 0s\n",
      " 18600K .......... .......... .......... .......... .......... 93%  291M 0s\n",
      " 18650K .......... .......... .......... .......... .......... 93%  257M 0s\n",
      " 18700K .......... .......... .......... .......... .......... 93%  283M 0s\n",
      " 18750K .......... .......... .......... .......... .......... 93%  258M 0s\n",
      " 18800K .......... .......... .......... .......... .......... 94%  248M 0s\n",
      " 18850K .......... .......... .......... .......... .......... 94%  251M 0s\n",
      " 18900K .......... .......... .......... .......... .......... 94%  298M 0s\n",
      " 18950K .......... .......... .......... .......... .......... 94%  293M 0s\n",
      " 19000K .......... .......... .......... .......... .......... 95%  259M 0s\n",
      " 19050K .......... .......... .......... .......... .......... 95%  284M 0s\n",
      " 19100K .......... .......... .......... .......... .......... 95%  321M 0s\n",
      " 19150K .......... .......... .......... .......... .......... 95%  319M 0s\n",
      " 19200K .......... .......... .......... .......... .......... 96%  292M 0s\n",
      " 19250K .......... .......... .......... .......... .......... 96%  302M 0s\n",
      " 19300K .......... .......... .......... .......... .......... 96%  351M 0s\n",
      " 19350K .......... .......... .......... .......... .......... 96%  329M 0s\n",
      " 19400K .......... .......... .......... .......... .......... 97%  279M 0s\n",
      " 19450K .......... .......... .......... .......... .......... 97%  277M 0s\n",
      " 19500K .......... .......... .......... .......... .......... 97%  313M 0s\n",
      " 19550K .......... .......... .......... .......... .......... 97%  340M 0s\n",
      " 19600K .......... .......... .......... .......... .......... 98%  313M 0s\n",
      " 19650K .......... .......... .......... .......... .......... 98%  258M 0s\n",
      " 19700K .......... .......... .......... .......... .......... 98%  320M 0s\n",
      " 19750K .......... .......... .......... .......... .......... 98%  355M 0s\n",
      " 19800K .......... .......... .......... .......... .......... 99%  297M 0s\n",
      " 19850K .......... .......... .......... .......... .......... 99%  266M 0s\n",
      " 19900K .......... .......... .......... .......... .......... 99%  347M 0s\n",
      " 19950K .......... .......... .......... .......... .......... 99%  278M 0s\n",
      " 20000K .......... .......... .......... .......              100%  251M=0.1s\n",
      "\n",
      "2025-06-10 23:53:14 (137 MB/s) - ‘/tmp/mobilenet.tar.gz’ saved [20518283/20518283]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# SSD MobileNet V2 FPNLite 640x640\n",
    "\n",
    "rm -R /tmp/checkpoint\n",
    "rm -R source_dir/checkpoint\n",
    "\n",
    "mkdir /tmp/checkpoint\n",
    "mkdir source_dir/checkpoint\n",
    "# wget -O /tmp/rxnnr50.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
    "# tar -zxvf /tmp/rxnnr50.tar.gz --strip-components 2 --directory source_dir/checkpoint faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint\n",
    "\n",
    "wget -O /tmp/mobilenet.tar.gz  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
    "tar -zxvf /tmp/mobilenet.tar.gz --strip-components 2 --directory source_dir/checkpoint ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e04a98",
   "metadata": {},
   "source": [
    "## Edit pipeline.config file\n",
    "\n",
    "The [`pipeline.config`](source_dir/pipeline.config) in the `source_dir` folder should be updated when you experiment with different models. The different config files are available [here](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2).\n",
    "\n",
    ">Note: The provided `pipeline.config` file works well with the `EfficientDet` model. You would need to modify it when working with other models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47483545",
   "metadata": {},
   "source": [
    "## Launch Training Job\n",
    "\n",
    "Now that we have a dataset, a docker image and some pretrained model weights, we can launch the training job. To do so, we create a [Sagemaker Framework](https://sagemaker.readthedocs.io/en/stable/frameworks/index.html), where we indicate the container name, name of the config file, number of training steps etc.\n",
    "\n",
    "The `run_training.sh` script does the following:\n",
    "* train the model for `num_train_steps` \n",
    "* evaluate over the val dataset\n",
    "* export the model\n",
    "\n",
    "Different metrics will be displayed during the evaluation phase, including the mean average precision. These metrics can be used to quantify your model performances and compare over the different iterations.\n",
    "\n",
    "You can also monitor the training progress by navigating to **Training -> Training Jobs** from the Amazon Sagemaker dashboard in the Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7175cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: tf2-object-detection-2025-06-10-23-54-25-931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-10 23:54:28 Starting - Starting the training job...\n",
      "2025-06-10 23:54:42 Starting - Preparing the instances for training...\n",
      "2025-06-10 23:55:25 Downloading - Downloading the training image.........\n",
      "2025-06-10 23:57:01 Training - Training image download completed. Training in progress...\u001b[34m2025-06-10 23:57:14,351 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-06-10 23:57:14,385 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-06-10 23:57:14,419 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-06-10 23:57:14,433 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/training\",\n",
      "        \"num_train_steps\": \"2000\",\n",
      "        \"pipeline_config_path\": \"pipeline.config\",\n",
      "        \"sample_1_of_n_eval_examples\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"tf2-object-detection-2025-06-10-23-54-25-931\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-503561426851/tf2-object-detection-2025-06-10-23-54-25-931/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_training.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"run_training.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-503561426851/tf2-object-detection-2025-06-10-23-54-25-931/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"tf2-object-detection-2025-06-10-23-54-25-931\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-503561426851/tf2-object-detection-2025-06-10-23-54-25-931/source/sourcedir.tar.gz\",\"module_name\":\"run_training.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"run_training.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/training\",\"--num_train_steps\",\"2000\",\"--pipeline_config_path\",\"pipeline.config\",\"--sample_1_of_n_eval_examples\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/training\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_STEPS=2000\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE_CONFIG_PATH=pipeline.config\u001b[0m\n",
      "\u001b[34mSM_HP_SAMPLE_1_OF_N_EVAL_EXAMPLES=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./run_training.sh --model_dir /opt/training --num_train_steps 2000 --pipeline_config_path pipeline.config --sample_1_of_n_eval_examples 1\"\u001b[0m\n",
      "\u001b[34m2025-06-10 23:57:14,433 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m===TRAINING THE MODEL==\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mI0610 23:57:20.891566 140318623758144 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mI0610 23:57:21.169348 140318623758144 config_util.py:552] Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0610 23:57:21.169497 140318623758144 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mW0610 23:57:21.191555 140318623758144 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0610 23:57:21.197461 140318623758144 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0610 23:57:21.198565 140318623758144 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mI0610 23:57:21.198645 140318623758144 dataset_builder.py:80] Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0610 23:57:21.204431 140318623758144 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0610 23:57:21.223889 140318623758144 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0610 23:57:26.838958 140318623758144 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mW0610 23:57:29.303875 140318623758144 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0610 23:57:30.532058 140318623758144 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI0610 23:57:39.117244 140290094298880 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0610 23:57:46.710714 140290094298880 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0610 23:57:52.942366 140318623758144 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0610 23:57:52.944598 140318623758144 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0610 23:57:52.945342 140318623758144 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0610 23:57:52.946016 140318623758144 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0610 23:57:52.948696 140318623758144 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0610 23:57:52.949362 140318623758144 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0610 23:57:52.950081 140318623758144 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0610 23:57:52.950716 140318623758144 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0610 23:57:52.953929 140318623758144 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI0610 23:57:52.954606 140318623758144 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mW0610 23:57:54.588628 140290104788736 deprecation.py:569] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mI0610 23:57:55.605420 140290104788736 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0610 23:58:01.540687 140290104788736 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0610 23:58:07.158911 140290104788736 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0610 23:58:12.910812 140290104788736 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 100 per-step time 0.560s\u001b[0m\n",
      "\u001b[34mI0610 23:58:49.872401 140318623758144 model_lib_v2.py:705] Step 100 per-step time 0.560s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.28729746,\n",
      " 'Loss/localization_loss': 0.46250418,\n",
      " 'Loss/regularization_loss': 0.15143184,\n",
      " 'Loss/total_loss': 0.9012335,\n",
      " 'learning_rate': 0.0319994}\u001b[0m\n",
      "\u001b[34mI0610 23:58:49.872682 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.28729746,\n",
      " 'Loss/localization_loss': 0.46250418,\n",
      " 'Loss/regularization_loss': 0.15143184,\n",
      " 'Loss/total_loss': 0.9012335,\n",
      " 'learning_rate': 0.0319994}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 200 per-step time 0.222s\u001b[0m\n",
      "\u001b[34mI0610 23:59:11.998731 140318623758144 model_lib_v2.py:705] Step 200 per-step time 0.222s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25630692,\n",
      " 'Loss/localization_loss': 0.44222042,\n",
      " 'Loss/regularization_loss': 0.15140758,\n",
      " 'Loss/total_loss': 0.84993494,\n",
      " 'learning_rate': 0.0373328}\u001b[0m\n",
      "\u001b[34mI0610 23:59:11.998968 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.25630692,\n",
      " 'Loss/localization_loss': 0.44222042,\n",
      " 'Loss/regularization_loss': 0.15140758,\n",
      " 'Loss/total_loss': 0.84993494,\n",
      " 'learning_rate': 0.0373328}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 300 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0610 23:59:34.135249 140318623758144 model_lib_v2.py:705] Step 300 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25834748,\n",
      " 'Loss/localization_loss': 0.34225306,\n",
      " 'Loss/regularization_loss': 0.15140827,\n",
      " 'Loss/total_loss': 0.7520088,\n",
      " 'learning_rate': 0.0426662}\u001b[0m\n",
      "\u001b[34mI0610 23:59:34.135483 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.25834748,\n",
      " 'Loss/localization_loss': 0.34225306,\n",
      " 'Loss/regularization_loss': 0.15140827,\n",
      " 'Loss/total_loss': 0.7520088,\n",
      " 'learning_rate': 0.0426662}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 400 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0610 23:59:56.275531 140318623758144 model_lib_v2.py:705] Step 400 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.18514726,\n",
      " 'Loss/localization_loss': 0.25906372,\n",
      " 'Loss/regularization_loss': 0.15131971,\n",
      " 'Loss/total_loss': 0.5955307,\n",
      " 'learning_rate': 0.047999598}\u001b[0m\n",
      "\u001b[34mI0610 23:59:56.275778 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.18514726,\n",
      " 'Loss/localization_loss': 0.25906372,\n",
      " 'Loss/regularization_loss': 0.15131971,\n",
      " 'Loss/total_loss': 0.5955307,\n",
      " 'learning_rate': 0.047999598}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 500 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:00:18.409718 140318623758144 model_lib_v2.py:705] Step 500 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20821309,\n",
      " 'Loss/localization_loss': 0.27619863,\n",
      " 'Loss/regularization_loss': 0.15129995,\n",
      " 'Loss/total_loss': 0.63571167,\n",
      " 'learning_rate': 0.053333}\u001b[0m\n",
      "\u001b[34mI0611 00:00:18.409938 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.20821309,\n",
      " 'Loss/localization_loss': 0.27619863,\n",
      " 'Loss/regularization_loss': 0.15129995,\n",
      " 'Loss/total_loss': 0.63571167,\n",
      " 'learning_rate': 0.053333}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 600 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:00:40.535651 140318623758144 model_lib_v2.py:705] Step 600 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.21137057,\n",
      " 'Loss/localization_loss': 0.351657,\n",
      " 'Loss/regularization_loss': 0.15120919,\n",
      " 'Loss/total_loss': 0.71423674,\n",
      " 'learning_rate': 0.0586664}\u001b[0m\n",
      "\u001b[34mI0611 00:00:40.535878 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.21137057,\n",
      " 'Loss/localization_loss': 0.351657,\n",
      " 'Loss/regularization_loss': 0.15120919,\n",
      " 'Loss/total_loss': 0.71423674,\n",
      " 'learning_rate': 0.0586664}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 700 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:01:02.686834 140318623758144 model_lib_v2.py:705] Step 700 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20327361,\n",
      " 'Loss/localization_loss': 0.3026221,\n",
      " 'Loss/regularization_loss': 0.15108967,\n",
      " 'Loss/total_loss': 0.6569854,\n",
      " 'learning_rate': 0.0639998}\u001b[0m\n",
      "\u001b[34mI0611 00:01:02.687068 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.20327361,\n",
      " 'Loss/localization_loss': 0.3026221,\n",
      " 'Loss/regularization_loss': 0.15108967,\n",
      " 'Loss/total_loss': 0.6569854,\n",
      " 'learning_rate': 0.0639998}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 800 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:01:24.795264 140318623758144 model_lib_v2.py:705] Step 800 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.18237968,\n",
      " 'Loss/localization_loss': 0.26826298,\n",
      " 'Loss/regularization_loss': 0.151043,\n",
      " 'Loss/total_loss': 0.60168564,\n",
      " 'learning_rate': 0.069333196}\u001b[0m\n",
      "\u001b[34mI0611 00:01:24.795490 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.18237968,\n",
      " 'Loss/localization_loss': 0.26826298,\n",
      " 'Loss/regularization_loss': 0.151043,\n",
      " 'Loss/total_loss': 0.60168564,\n",
      " 'learning_rate': 0.069333196}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 900 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:01:46.894342 140318623758144 model_lib_v2.py:705] Step 900 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20992953,\n",
      " 'Loss/localization_loss': 0.26987725,\n",
      " 'Loss/regularization_loss': 0.15108499,\n",
      " 'Loss/total_loss': 0.6308918,\n",
      " 'learning_rate': 0.074666604}\u001b[0m\n",
      "\u001b[34mI0611 00:01:46.894569 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.20992953,\n",
      " 'Loss/localization_loss': 0.26987725,\n",
      " 'Loss/regularization_loss': 0.15108499,\n",
      " 'Loss/total_loss': 0.6308918,\n",
      " 'learning_rate': 0.074666604}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1000 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:02:09.014125 140318623758144 model_lib_v2.py:705] Step 1000 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20760104,\n",
      " 'Loss/localization_loss': 0.33464515,\n",
      " 'Loss/regularization_loss': 0.15105733,\n",
      " 'Loss/total_loss': 0.6933036,\n",
      " 'learning_rate': 0.08}\u001b[0m\n",
      "\u001b[34mI0611 00:02:09.014357 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.20760104,\n",
      " 'Loss/localization_loss': 0.33464515,\n",
      " 'Loss/regularization_loss': 0.15105733,\n",
      " 'Loss/total_loss': 0.6933036,\n",
      " 'learning_rate': 0.08}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1100 per-step time 0.230s\u001b[0m\n",
      "\u001b[34mI0611 00:02:32.003534 140318623758144 model_lib_v2.py:705] Step 1100 per-step time 0.230s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.26328507,\n",
      " 'Loss/localization_loss': 0.31362745,\n",
      " 'Loss/regularization_loss': 0.15086086,\n",
      " 'Loss/total_loss': 0.72777337,\n",
      " 'learning_rate': 0.07999918}\u001b[0m\n",
      "\u001b[34mI0611 00:02:32.003784 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.26328507,\n",
      " 'Loss/localization_loss': 0.31362745,\n",
      " 'Loss/regularization_loss': 0.15086086,\n",
      " 'Loss/total_loss': 0.72777337,\n",
      " 'learning_rate': 0.07999918}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1200 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:02:54.107691 140318623758144 model_lib_v2.py:705] Step 1200 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.19728945,\n",
      " 'Loss/localization_loss': 0.21253005,\n",
      " 'Loss/regularization_loss': 0.15067506,\n",
      " 'Loss/total_loss': 0.56049454,\n",
      " 'learning_rate': 0.079996705}\u001b[0m\n",
      "\u001b[34mI0611 00:02:54.107912 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.19728945,\n",
      " 'Loss/localization_loss': 0.21253005,\n",
      " 'Loss/regularization_loss': 0.15067506,\n",
      " 'Loss/total_loss': 0.56049454,\n",
      " 'learning_rate': 0.079996705}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1300 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:03:16.216210 140318623758144 model_lib_v2.py:705] Step 1300 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25747004,\n",
      " 'Loss/localization_loss': 0.33843324,\n",
      " 'Loss/regularization_loss': 0.1506724,\n",
      " 'Loss/total_loss': 0.7465757,\n",
      " 'learning_rate': 0.0799926}\u001b[0m\n",
      "\u001b[34mI0611 00:03:16.216434 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.25747004,\n",
      " 'Loss/localization_loss': 0.33843324,\n",
      " 'Loss/regularization_loss': 0.1506724,\n",
      " 'Loss/total_loss': 0.7465757,\n",
      " 'learning_rate': 0.0799926}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1400 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:03:38.326955 140318623758144 model_lib_v2.py:705] Step 1400 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.19610387,\n",
      " 'Loss/localization_loss': 0.3128763,\n",
      " 'Loss/regularization_loss': 0.15047161,\n",
      " 'Loss/total_loss': 0.6594518,\n",
      " 'learning_rate': 0.07998685}\u001b[0m\n",
      "\u001b[34mI0611 00:03:38.327180 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.19610387,\n",
      " 'Loss/localization_loss': 0.3128763,\n",
      " 'Loss/regularization_loss': 0.15047161,\n",
      " 'Loss/total_loss': 0.6594518,\n",
      " 'learning_rate': 0.07998685}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1500 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:04:00.427671 140318623758144 model_lib_v2.py:705] Step 1500 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.19199821,\n",
      " 'Loss/localization_loss': 0.24217106,\n",
      " 'Loss/regularization_loss': 0.15031588,\n",
      " 'Loss/total_loss': 0.5844852,\n",
      " 'learning_rate': 0.07997945}\u001b[0m\n",
      "\u001b[34mI0611 00:04:00.427901 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.19199821,\n",
      " 'Loss/localization_loss': 0.24217106,\n",
      " 'Loss/regularization_loss': 0.15031588,\n",
      " 'Loss/total_loss': 0.5844852,\n",
      " 'learning_rate': 0.07997945}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1600 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:04:22.552910 140318623758144 model_lib_v2.py:705] Step 1600 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.1783349,\n",
      " 'Loss/localization_loss': 0.22019945,\n",
      " 'Loss/regularization_loss': 0.1500384,\n",
      " 'Loss/total_loss': 0.5485728,\n",
      " 'learning_rate': 0.079970405}\u001b[0m\n",
      "\u001b[34mI0611 00:04:22.553135 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.1783349,\n",
      " 'Loss/localization_loss': 0.22019945,\n",
      " 'Loss/regularization_loss': 0.1500384,\n",
      " 'Loss/total_loss': 0.5485728,\n",
      " 'learning_rate': 0.079970405}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1700 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:04:44.679716 140318623758144 model_lib_v2.py:705] Step 1700 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.18609422,\n",
      " 'Loss/localization_loss': 0.2635635,\n",
      " 'Loss/regularization_loss': 0.1497023,\n",
      " 'Loss/total_loss': 0.59936005,\n",
      " 'learning_rate': 0.07995972}\u001b[0m\n",
      "\u001b[34mI0611 00:04:44.679937 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.18609422,\n",
      " 'Loss/localization_loss': 0.2635635,\n",
      " 'Loss/regularization_loss': 0.1497023,\n",
      " 'Loss/total_loss': 0.59936005,\n",
      " 'learning_rate': 0.07995972}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1800 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:05:06.793174 140318623758144 model_lib_v2.py:705] Step 1800 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.19576009,\n",
      " 'Loss/localization_loss': 0.25713205,\n",
      " 'Loss/regularization_loss': 0.149292,\n",
      " 'Loss/total_loss': 0.6021841,\n",
      " 'learning_rate': 0.0799474}\u001b[0m\n",
      "\u001b[34mI0611 00:05:06.793426 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.19576009,\n",
      " 'Loss/localization_loss': 0.25713205,\n",
      " 'Loss/regularization_loss': 0.149292,\n",
      " 'Loss/total_loss': 0.6021841,\n",
      " 'learning_rate': 0.0799474}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1900 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:05:28.923446 140318623758144 model_lib_v2.py:705] Step 1900 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.15626693,\n",
      " 'Loss/localization_loss': 0.28391296,\n",
      " 'Loss/regularization_loss': 0.14895073,\n",
      " 'Loss/total_loss': 0.58913064,\n",
      " 'learning_rate': 0.07993342}\u001b[0m\n",
      "\u001b[34mI0611 00:05:28.923682 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.15626693,\n",
      " 'Loss/localization_loss': 0.28391296,\n",
      " 'Loss/regularization_loss': 0.14895073,\n",
      " 'Loss/total_loss': 0.58913064,\n",
      " 'learning_rate': 0.07993342}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 2000 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mI0611 00:05:51.043056 140318623758144 model_lib_v2.py:705] Step 2000 per-step time 0.221s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.16892079,\n",
      " 'Loss/localization_loss': 0.21172942,\n",
      " 'Loss/regularization_loss': 0.14858957,\n",
      " 'Loss/total_loss': 0.5292398,\n",
      " 'learning_rate': 0.07991781}\u001b[0m\n",
      "\u001b[34mI0611 00:05:51.043281 140318623758144 model_lib_v2.py:708] {'Loss/classification_loss': 0.16892079,\n",
      " 'Loss/localization_loss': 0.21172942,\n",
      " 'Loss/regularization_loss': 0.14858957,\n",
      " 'Loss/total_loss': 0.5292398,\n",
      " 'learning_rate': 0.07991781}\u001b[0m\n",
      "\u001b[34m==EVALUATING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mW0611 00:05:58.428638 140200656996160 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mI0611 00:05:58.428812 140200656996160 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0611 00:05:58.428887 140200656996160 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mI0611 00:05:58.428963 140200656996160 config_util.py:552] Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mW0611 00:05:58.429088 140200656996160 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0611 00:05:58.789736 140200656996160 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0611 00:05:58.790672 140200656996160 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mI0611 00:05:58.790751 140200656996160 dataset_builder.py:80] Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mW0611 00:05:58.790821 140200656996160 dataset_builder.py:86] num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mW0611 00:05:58.792516 140200656996160 dataset_builder.py:93] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0611 00:05:58.793837 140200656996160 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0611 00:05:58.812548 140200656996160 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0611 00:06:02.248938 140200656996160 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0611 00:06:03.044546 140200656996160 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI0611 00:06:05.548935 140200656996160 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34mI0611 00:06:05.549532 140200656996160 checkpoint_utils.py:177] Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI0611 00:06:10.277586 140200656996160 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0611 00:06:20.549916 140200656996160 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0611 00:06:24.614420 140200656996160 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI0611 00:06:24.652800 140200656996160 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mW0611 00:06:24.993716 140200656996160 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI0611 00:06:31.617102 140200656996160 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI0611 00:06:35.984477 140200656996160 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mI0611 00:06:38.468085 140200656996160 coco_evaluation.py:293] Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI0611 00:06:38.471980 140200656996160 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mI0611 00:06:38.484088 140200656996160 coco_tools.py:138] DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.618081 140200656996160 model_lib_v2.py:1015] Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.102100\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.636124 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.102100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.224388\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.637526 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.224388\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.087982\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.638495 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.087982\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): 0.042442\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.639459 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): 0.042442\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.325574\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.640445 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.325574\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.542575\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.641408 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.542575\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.023502\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.642387 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.023502\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.108283\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.643315 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.108283\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.156823\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.644284 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.156823\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): 0.094678\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.645236 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): 0.094678\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.459742\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.646128 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.459742\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.633080\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.647117 140200656996160 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.633080\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.450678\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.647869 140200656996160 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.450678\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 0.262799\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.648605 140200656996160 model_lib_v2.py:1018] #011+ Loss/classification_loss: 0.262799\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.148585\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.649357 140200656996160 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.148585\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 0.862062\u001b[0m\n",
      "\u001b[34mI0611 00:06:46.650087 140200656996160 model_lib_v2.py:1018] #011+ Loss/total_loss: 0.862062\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI0611 00:11:05.648047 140200656996160 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mI0611 00:11:14.661697 140200656996160 checkpoint_utils.py:231] Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mRunning per image evaluation...\u001b[0m\n",
      "\u001b[34mEvaluate annotation type *bbox*\u001b[0m\n",
      "\u001b[34mDONE (t=7.93s).\u001b[0m\n",
      "\u001b[34mAccumulating evaluation results...\u001b[0m\n",
      "\u001b[34mDONE (t=0.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.024\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\u001b[0m\n",
      "\u001b[34m==EXPORTING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mW0611 00:11:19.533030 140130318567232 deprecation.py:641] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mI0611 00:11:23.146365 140130318567232 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0611 00:11:30.666853 140130318567232 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0611 00:11:33.720665 140130318567232 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_predictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\u001b[0m\n",
      "\u001b[34mI0611 00:11:34.865287 140130318567232 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f71f0040790>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.137872 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f71f0040790>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f7194213c40>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393021 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f7194213c40>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f719434b4f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393203 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f719434b4f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71e03a84f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393293 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71e03a84f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f71e03a8910>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393371 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f71e03a8910>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71e0164d00>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393444 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71e0164d00>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71e0164f70>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393529 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71e0164f70>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f71942f0bb0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393609 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f71942f0bb0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71941be070>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393703 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71941be070>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71941be4c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393784 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71941be4c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f71941be3a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393863 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f71941be3a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71941be9a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.393944 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71941be9a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71941bebb0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394024 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71941bebb0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f719407c5b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394110 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f719407c5b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71e0281ac0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394186 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71e0281ac0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f719416a070>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394276 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f719416a070>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f719416ad60>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394352 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f719416ad60>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7194366df0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394492 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7194366df0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71e0245e80>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394574 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71e0245e80>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71e02459d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394661 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71e02459d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71e02456d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394742 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71e02456d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71e07ca130>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394818 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71e07ca130>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bf3d4f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.394923 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bf3d4f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f714bf3d9d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.395015 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f714bf3d9d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bf3db20>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.395105 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bf3db20>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f714bf3da30>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.395195 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f714bf3da30>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bf3d100>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.395276 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bf3d100>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71941d93d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.395346 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71941d93d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71941d9340>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.395426 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71941d9340>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71940a3d00>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.395558 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71940a3d00>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bec10a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.395664 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bec10a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f714bec1700>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.395782 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f714bec1700>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bec19a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.395896 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bec19a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f714bec11c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.396013 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f714bec11c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bec12e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.396141 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f714bec12e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7194265d90>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.396275 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7194265d90>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71942654c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.396363 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71942654c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71941ae910>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.396447 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71941ae910>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f717c1ce3a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.396559 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f717c1ce3a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71940af370>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.396707 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71940af370>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71940af100>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.396847 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71940af100>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71940afd60>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.396969 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71940afd60>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71940affd0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.397115 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f71940affd0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f719426f250>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.397196 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f719426f250>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f719426fa90>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0611 00:11:37.397285 140130318567232 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f719426fa90>, because it is not built.\u001b[0m\n",
      "\u001b[34mI0611 00:11:48.697921 140130318567232 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI0611 00:12:06.161472 140130318567232 builder_impl.py:804] Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI0611 00:12:12.953256 140130318567232 fingerprinting_utils.py:48] Writing fingerprint to /tmp/exported/saved_model/fingerprint.pb\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34mI0611 00:12:13.366753 140130318567232 config_util.py:253] Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34m2025-06-11 00:12:14,845 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-06-11 00:12:32 Uploading - Uploading generated training model\n",
      "2025-06-11 00:12:32 Completed - Training job completed\n",
      "Training seconds: 1043\n",
      "Billable seconds: 1043\n"
     ]
    }
   ],
   "source": [
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_s3_prefix,\n",
    "    container_local_output_path='/opt/training/'\n",
    ")\n",
    "\n",
    "estimator = CustomFramework(\n",
    "    role=role,\n",
    "    image_uri=container,\n",
    "    entry_point='run_training.sh',\n",
    "    source_dir='source_dir/',\n",
    "    hyperparameters={\n",
    "        \"model_dir\": \"/opt/training\",        \n",
    "        \"pipeline_config_path\": \"pipeline.config\",\n",
    "        \"num_train_steps\": \"2000\",    \n",
    "        \"sample_1_of_n_eval_examples\": \"1\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    disable_profiler=True,\n",
    "    base_job_name='tf2-object-detection'\n",
    ")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84545881",
   "metadata": {},
   "source": [
    "You should be able to see your model training in the AWS webapp as shown below:\n",
    "![ECR Example](../data/example_trainings.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9844f25",
   "metadata": {},
   "source": [
    "## Improve on the initial model\n",
    "\n",
    "Most likely, this initial experiment did not yield optimal results. However, you can make multiple changes to the `pipeline.config` file to improve this model. One obvious change consists in improving the data augmentation strategy. The [`preprocessor.proto`](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) file contains the different data augmentation method available in the Tf Object Detection API. Justify your choices of augmentations in the write-up.\n",
    "\n",
    "Keep in mind that the following are also available:\n",
    "* experiment with the optimizer: type of optimizer, learning rate, scheduler etc\n",
    "* experiment with the architecture. The Tf Object Detection API model zoo offers many architectures. Keep in mind that the pipeline.config file is unique for each architecture and you will have to edit it.\n",
    "* visualize results on the test frames using the `2_deploy_model` notebook available in this repository.\n",
    "\n",
    "In the cell below, write down all the different approaches you have experimented with, why you have chosen them and what you would have done if you had more time and resources. Justify your choices using the tensorboard visualizations (take screenshots and insert them in your write-up), the metrics on the evaluation set and the generated animation you have created with [this tool](../2_run_inference/2_deploy_model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17284a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your write-up goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
